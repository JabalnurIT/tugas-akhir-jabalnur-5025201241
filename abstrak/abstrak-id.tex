\chapter*{ABSTRAK}
\addcontentsline{toc}{chapter}{ABSTRAK}

\vspace{2ex}

\begingroup
% Menghilangkan padding
\setlength{\tabcolsep}{0pt}

\noindent
\begin{tabularx}{\textwidth}{l >{\centering}m{2em} X}
  Nama Mahasiswa    & : & \name{}         \\

  Judul Tugas Akhir & : & \tatitle{}      \\

  Pembimbing        & : & 1. \advisor{}   \\
\end{tabularx}
\endgroup

% Ubah paragraf berikut dengan abstrak dari tugas akhir
% Framework pemrosesan data skala besar seperti \textit{Apache Spark} telah memungkinkan \textit{developer} untuk memproses petabyte data dengan aplikasi \textit{Data-Intensive Scalable Computing (DISC)}. Seperti halnya perangkat lunak lainnya, kesalahan dalam aplikasi \textit{DISC} adalah hal yang umum. Kesalahan tersebut dapat timbul karena dataset input yang tidak bersih atau implementasi aplikasi, yang membuat \textit{developer} harus mengidentifikasi akar penyebab di antara miliaran data input. Proses \textit{Data Provenance} dan \textit{debugging} otomatis memerlukan instrumentasi aplikasi \textit{DISC} atau melakukan \textit{search-based fault isolation} yang memakan banyak sumber daya.

% Penelitian ini bertujuan untuk menunjukkan potensi penggunaan \textit{language model} untuk menghasilkan dataset input minimal namun dapat mereproduksi kesalahan yang sama seperti yang diamati pada data masukan skala besar aslinya. Kami membuat \textit{FISUM} (\textit{Fault-inducing Inputs Summarization}), yang melatih model dengan \textit{faulty input} secara historis untuk menghasilkan baris salah baru yang minimal. \textit{FISUM} menggunakan \textit{Data Provenance Engine} yang dibangun untuk \textit{Apache Spark}, untuk memulihkan input yang menyebabkan kesalahan. Kemudian melatih sebuah \textit{lightweight language model}, \textit{DistilGPT}, menggunakan input yang menyebabkan kegagalan ini untuk menghasilkan input minimal yang mengungkapkan kesalahan yang sama.

% Pada percobaan dengan aplikasi \textit{DISC} bermasalah yang telah ada, bahkan dengan model ringan, \textit{FISUM} secara efektif dapat merangkum input yang menyebabkan kesalahan, mengurangi input asli dari alat \textit{data provenance} sebesar 99\%, namun masih dapat menyebabkan kesalahan yang sama. \textit{FISUM} menghasilkan \textit{faulty input} dalam waktu kurang dari 50 milidetik per baris, rata-rata.

Framework pemrosesan data skala besar seperti Apache Spark telah memungkinkan \textit{developer} untuk memproses petabyte data dengan aplikasi \textit{Data-Intensive Scalable Computing (DISC)}. Seperti halnya perangkat lunak lainnya, kesalahan dalam aplikasi DISC adalah hal yang umum. Kesalahan tersebut dapat timbul karena dataset input yang tidak bersih atau implementasi aplikasi, yang membuat \textit{developer} harus mengidentifikasi akar penyebab di antara miliaran data input. Proses \textit{Data Provenance} dan \textit{debugging} otomatis memerlukan instrumentasi aplikasi DISC atau melakukan \textit{search-based fault isolation} yang memakan banyak sumber daya. Penelitian ini bertujuan untuk menunjukkan potensi penggunaan \textit{language model} untuk menghasilkan dataset input minimal namun dapat mereproduksi kesalahan yang sama seperti yang diamati pada data masukan skala besar aslinya. Kami membuat FISUM (\textit{Fault-inducing Inputs Summarization}), yang melatih model dengan \textit{faulty input} secara historis untuk menghasilkan baris salah baru yang minimal dan memiliki karakteristik yang sama dengan data aslinya.

FISUM menggunakan Titian, sebuah \textit{Data Provenance Engine} yang dibangun untuk Apache Spark, untuk memulihkan input yang menyebabkan kesalahan. \textit{Data Provenance Engine} merupakan sebuah sistem yang melacak asal-usul, sejarah, dan perjalanan data dalam sebuah sistem komputasi untuk memudahkan dalam mengidentifikasi sumber kesalahan dan memahami transformasi data dari sumber aslinya hingga ke bentuk akhirnya. Titian kemudian ditanamkan ke dalam aplikasi DISC yang memiliki keluaran bermasalah untuk menemukan \textit{Faulty Input}, yaitu baris data pada dataset yang menjadi penyebab keluaran bermasalah pada aplikasi DISC. Sebuah \textit{lightweight language model}, DistilGPT2 milik HuggingFace \textit{Faulty Input} kemudian dilatih menggunakan dataset awal milik aplikasi DISC untuk membiasakan model tersebut dengan dataset aplikasi, kemudian model tersebut dilatih kembali dengan menggunakan \textit{Faulty Input} dari Titian untuk memahami karakteristik dari \textit{Faulty Input} tersebut. DistilGPT2 yang telah dilatih akhirnya dapat digunakan untuk menghasilkan \textit{Faulty Input} baru yang memiliki ukuran yang jauh lebih kecil dari ukuran aslinya dengan tetap mempertahankan kemiripan karakteristik kesalahan pada \textit{Faulty Input} awal dalam waktu yang cukup singkat.

Percobaan dilakukan dengan menguji 16 \textit{Benchmark Application} yang merupakan aplikasi DISC dengan menghitung tingkat akurasi FISUM dalam menemukan \textit{Faulty Input} pada dataset aplikasi, menghitung tingkat akurasi dari kesalahan yang dimiliki oleh \textit{Faulty Input} baru dan menghitung \textit{Mean Square Error (MSE)} dari karakteristik yang dimiliki oleh \textit{Faulty Input} awal dan baru. FISUM secara efektif dapat menemukan \textit{Faulty Input} pada aplikasi DISC dengan akurasi 100\%, dapat merangkum \textit{Faulty Input} dengan tingkat akurasi 99.4\% dalam waktu kurang dari 0.082 detik per baris, dan dapat menyajikan kemiripan karakteristik dari \textit{Faulty Input} awal dan baru dengan MSE sebesar 0.262.


% Ubah kata-kata berikut dengan kata kunci dari tugas akhir
Kata Kunci: \emph{Debugging}, \emph{Generative AI}, \emph{Faults}, \emph{Language Models}.
